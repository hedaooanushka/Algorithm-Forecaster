<!DOCTYPE html>
<html>
<head>
	<!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="MATHEMATICS.css">
    <script src="http://code.jquery.com/jquery-3.5.1.js"></script>
    <!-- <script src="//code.jquery.com/jquery-3.5.1.min.js"></script> -->

	<title>Mathematics</title>
</head>
<body>
	<!-- NavBar --> 
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
  <a class="navbar-brand" href="ALGORITHM.html" style="letter-spacing: 4px;"><i class="fa fa-code" aria-hidden="true"></i> ALGORITHM FORECASTER</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav mr-auto" id="highlight">
      <li class="nav-item">
        <a class="nav-link" href="MACHINE.html" id="ml">Machine Learning <!-- <span class="sr-only">(current)</span> --></a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="MATHEMATICS.html" style="font-weight: bold; color: white;">Mathematics</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="CRYPTOGRAPHY.html" id="c">Cryptography</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="SEARCHING.html" id="se">Searching</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="SORTING.html" id="so">Sorting</a>
      </li>
    </ul>
    <form class="form-inline my-2 my-lg-0">
      <input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search">
      <button class="btn btn-outline-success my-2 my-sm-0" type="submit">Search</button>
    </form>
  </div>
</nav>

<div id="heromath">
  <div id="child1">
      <p id="domain" data-text="[Neon_Light]"> MATHEMATICS </p>
	<div class="step step-1">
        <p style="color: white; margin-left: 30px; font-size: 23px;"> Which sub-domain is your project related to? </p>
        <input type="button" class="button q1" value="Abstract Algebra" onclick="buttonclick(2)"/> 
        <input type="button" class="button q1" value="Computational Algebra" onclick="buttonclick(3)"/> 
        <input type="button" class="button q1" value="Geometry" onclick="buttonclick(4)"/>
        <br>
        <br>
        <input type="button" class="button q1" value="Numerical theory Algorithms" onclick="buttonclick(5)"/> 
        <input type="button" class="button q1" value="Linear Algebra" onclick="buttonclick(6)"/> 
    </div>

    <div class="step step-2">
    	<form class="form">
		<select name="AbstractAlgebra" id="abstract" class="search1">
			<option value="Chein-Search" id="Volvo">Do you want to find the roots of a polynomial over a finite field?</option>
			<option value="Schreier-Sims" id="Saab">Do you want to compute a BSGS of a permutation group?</option>
			<option value="Todd-Coxeter">Do you want to generate Cosets?</option>
			<input type="button" value="Click" id="click1">
		</select>
        </form>
        <p class="ans ans1"></p> 
    </div>

    <div class="step step-3">
    	<form class="form">
		<select name="ComputationalAlgebra" id="computational" class="search1">
			<option value="Buchbergers">Do you want to find Grobner Basis?</option>
			<option value="Cantor-Zassenhaus">Do you want to factor polynomials over a finite field?</option>
			<option value="Knuth-Bendix-Completion">Do you want an algorithm for rewiting rule systems?</option>
			<option value="Pollards-Kangaroo">Do you want an algorithm for discrete logarithm problem?</option>
			<option value="Polynomial-Long-Division">Do you want to divide a polynomial by another polynomial of lower degree?</option>
			<option value="Risch">Do you want a powerful algorithm for indefinite integration?</option>
			<option value="Risch-Norman">Do you want a faster algorithm for indefinite integration?</option>
			<input type="button" value="Click" id="click2">
		</select>
        </form>
        <p class="ans ans2"></p> 
    </div>

    <div class="step step-4">
    	<form class="form">
		<select name="Geometry" id="geometry" class="search1">
			<option value="Closest-Pair">Want to calculate smallest distance between two points from a set of points?</option>
			<option value="Gilbert-Johnson-Keerthi-Distance">Want to calculate smallest distance between two convex shapes?</option>
			<option value="Euclidean-Distance-Transform">Want to calculate distance between every point in a Grid & discrete collection of points</option>
			<option value="Nearest-Neighbour-Search">Do you want an algorithm to find the nearest point or points to a query point?</option>
			<option value="Collision-Detection">Do you want to check collison or intersection of two given solids?</option>
			<option value="Cone">Do you want an algorithm to identify surface points?</option>
			<option value="Jump-and-Walk">Want an algorithm for point location in triangulations?</option>
			<option value="Laplacian-Smoothing">Do you want to smooth a polygonal mesh?</option>
			<option value="Bentley-Ottmann">do you want to check whether lines intersect?</option>
			<option value="Ray-Casting">Want a faster algorithm to check whether a point lies in a polygon?</option>
			<option value="Winding-Number">Want an accurate algorithm to check whether a point lies in a polygon?</option>
			<option value="Shoelace">Do you want to Determine area of a polygon?</option>
			<input type="button" value="Click" id="click3">
		</select>
        </form>
        <p class="ans ans3"></p> 
    </div>

    <div class="step step-5">
    	<form class="form">
		<select name="NumericalAnalysis" id="numerical" class="search1">
			<option value="Euclidean" id="Volvo">Want an algorithm for calcuating GCD?</option>
			<option value="Extended-Euclidean" id="Saab">Want to solve equations of the form ax+by=c?</option>
			<option value="Schonhage-Strassen">Want Algorithms for multiplication?</option>
			<option value="Odlyzko-Schonhage">Want to calculate Non trivial zeroes of a riemann zeta function?</option>
			<option value="Borwein's">Want an algorithm to calculate value of  1/π?</option>
			<option value="Chudnovsky">Want an algorithm to compute the digits of pi(π)?</option>
			<option value="Bailey-Borwein-Plouffe-Formula">Want an algorithm to compute the nth binary digit of pi?</option>
			<option value="Addition-chain-Exponentiation">  Want an algorithm for exponentiation by positive integer powers?</option>
			<option value="Exponentiating-By-Squaring"> Algorithm for fast calculation of large integer powers of a number?</option>
			<input type="button" value="Click" id="click4">
		</select>
        </form>
        <p class="ans ans4"></p> 
    </div>

    <div class="step step-6">
    	<form class="form">
		<select name="LinearAlgebra" id="linear" class="search1">
			<option value="Rayleigh-Quotient-Iteration">Want an algorithm to calculate Eigenvalue?</option>
			<option value="Gram-Schmidt">Do you want to orthogonalize a set of vectors?</option>
			<option value="Strassen">Want an algorithm for matrix multiplication?</option>
			<option value="Freivalds">Want an algorithm to verify matrix multiplication?</option>
			<option value="Gauss-Jordan-Elimination">Want an algorithm for solving system of linear equations?</option>
			<input type="button" value="Click" id="click5">
		</select>
        </form>
        <p class="ans ans5"></p> 
    </div>
</div>

<div id="child2" > 
<div class="card border-light mb-3 Buchbergers search" style="max-width: 44rem;">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Buchberger's Algorithm</h5>
      <p class="card-text">In computational algebraic geometry and computational commutative algebra, Buchberger's algorithm is a method of transforming a given set of generators for a polynomial ideal into a Gröbner basis with respect to some monomial order. It was invented by Austrian mathematician Bruno Buchberger. One can view it as a generalization of the Euclidean algorithm for univariate GCD computation and of Gaussian elimination for linear systems. The computational complexity of Buchberger's algorithm is very difficult to estimate, because of the number of choices that may dramatically change the computation time.
      </p>
    </div>
  </div>

  <div class="card border-light mb-3 Schreier-Sims search" style="max-width: 44rem;">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Schreier-Sims Algorithm</h5>
      <p class="card-text">The Schreier–Sims algorithm is an algorithm in computational group theory, named after the mathematicians Otto Schreier and Charles Sims. This algorithm can find the order of a finite permutation group, test membership. The algorithm is an efficient method of computing a base and strong generating set (BSGS) of a permutation group. In particular, an SGS determines the order of a group and makes it easy to test membership in the group. Since the SGS is critical for many algorithms in computational group theory, computer algebra systems typically rely on the Schreier–Sims algorithm for efficient calculations in groups.
      </p>
    </div>
  </div>

<div class="card border-light mb-3 Chein-Search search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Chein Search Algorithm</h5>
      <p class="card-text">In abstract algebra, the Chien search, named after Robert Tienwen Chien, is a fast algorithm for determining roots of polynomials defined over a finite field. Chien search is commonly used to find the roots of error-locator polynomials encountered in decoding Reed-Solomon codes and BCH codes.<br><br>
      	The problem is to find the roots of the polynomial over the finite field:<br>
The roots may be found using brute force: there are a finite number of x, so the polynomial can be evaluated for each element. If the polynomial evaluates to zero, then that element is a root.
      </p>
    </div>
  </div>


<div class="card border-light mb-3 Todd-Coxeter search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Todd-Coxeter Algorithm</h5>
      <p class="card-text">For finite presentations, those with a finite set of generators and a finite set of relations between them, the Todd-Coxeter algorithm is able to give a list of all elements of a finite group in an (unknown) finite time. In fact, the algorithm is able to do more: enumerate the cosets of a finite-index finitely generated subgroup. Or, more specificially, it is able to find a faithful group action with a given finitely generated stabilizer.<br><br>
      	The Todd–Coxeter algorithm can be applied to infinite groups and is known to terminate in a finite number of steps, provided that the index of H in G is finite. On the other hand, for a general pair consisting of a group presentation and a subgroup, its running time is not bounded by any computable function of the index of the subgroup and the size of the input data.
      </p>
    </div>
  </div>


<div class="card border-light mb-3 Cantor-Zassenhaus search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Cantor-Zassenhaus Algorithm</h5>
      <p class="card-text">In computational algebra, the Cantor–Zassenhaus algorithm is a method for factoring polynomials over finite fields (also called Galois fields).
The algorithm consists mainly of exponentiation and polynomial GCD computations. It was invented by David G. Cantor and Hans Zassenhaus in 1981.
It is arguably the dominant algorithm for solving the problem, having replaced the earlier Berlekamp's algorithm of 1967. It is currently implemented in many computer algebra systems.
      </p>
    </div>
  </div>


<div class="card border-light mb-3 Knuth-Bendix-Completion search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Knuth-Bendix-Completion  Algorithm</h5>
      <p class="card-text">The Knuth–Bendix completion algorithm (named after Donald Knuth and Peter Bendix[1]) is a semi-decision[2][3] algorithm for transforming a set of equations (over terms) into a confluent term rewriting system. When the algorithm succeeds, it effectively solves the word problem for the specified algebra.
      </p>
    </div>
  </div>


<div class="card border-light mb-3 Pollards-Kangaroo search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Pollard's-Kangaroo Algorithm</h5>
      <p class="card-text">In computational number theory and computational algebra, Pollard's kangaroo algorithm (also Pollard's lambda algorithm, see Naming below) is an algorithm for solving the discrete logarithm problem. The algorithm was introduced in 1978 by the number theorist J. M. Pollard, in the same paper as his better-known Pollard's rho algorithm for solving the same problem.[1] Although Pollard described the application of his algorithm to the discrete logarithm problem in the multiplicative group of units modulo a prime p, it is in fact a generic discrete logarithm algorithm—it will work in any finite cyclic group.<br>
      	Pollard gives the time complexity of the algorithm as O(root of (b-a)), based on a probabilistic argument.<br>
      	The algorithm is well known by two names.<br>

<ul><li>The first is "Pollard's kangaroo algorithm".</li>
<li>The first is "Pollard's lambda algorithm".</li></ul>
      </p>
    </div>
  </div>



<div class="card border-light mb-3 Polynomial-Long-Division search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Polynomial-Long-Division Algorithm</h5>
      <p class="card-text">In algebra, polynomial long division is an algorithm for dividing a polynomial by another polynomial of the same or lower degree, a generalised version of the familiar arithmetic technique called long division. It can be done easily by hand, because it separates an otherwise complex division problem into smaller ones. Sometimes using a shorthand version called synthetic division is faster, with less writing and fewer calculations. Another abbreviated method is polynomial short division (Blomqvist's method).<br>

Polynomial long division is an algorithm that implements the Euclidean division of polynomials, which starting from two polynomials A (the dividend) and B (the divisor) produces, if B is not zero, a quotient Q and a remainder R such that<br>

A = BQ + R,
and either R = 0 or the degree of R is lower than the degree of B. These conditions uniquely define Q and R, which means that Q and R do not depend on the method used to compute them.<br>

The result R = 0 occurs if and only if the polynomial A has B as a factor. Thus long division is a means for testing whether one polynomial has another as a factor, and, if it does, for factoring it out. For example, if a root r of A is known, it can be factored out by dividing A by (x–r).
      </p>
    </div>
  </div>


<div class="card border-light mb-3 Risch search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Risch Algorithm</h5>
      <p class="card-text">In symbolic computation, the Risch algorithm is an algorithm for indefinite integration. It is used in some computer algebra systems to find antiderivatives. The algorithm transforms the problem of integration into a problem in algebra. It is based on the form of the function being integrated and on methods for integrating rational functions, radicals, logarithms, and exponential functions. Risch called it a decision procedure, because it is a method for deciding whether a function has an elementary function as an indefinite integral, and if it does, for determining that indefinite integral.<br>
      	The Risch algorithm is used to integrate elementary functions. These are functions obtained by composing exponentials, logarithms, radicals, trigonometric functions, and the four arithmetic operations (+ − × ÷).
      </p>
    </div>
  </div>

<div class="card border-light mb-3 Risch-Norman search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Risch-Norman Algorithm</h5>
      <p class="card-text"> The Risch–Norman algorithm is a simpler, faster, but less powerful variant of Risch algorithm that was developed in 1976 by Arthur Norman. <br>
      	In symbolic computation, the Risch algorithm is an algorithm for indefinite integration. It is used in some computer algebra systems to find antiderivatives. The algorithm transforms the problem of integration into a problem in algebra. It is based on the form of the function being integrated and on methods for integrating rational functions, radicals, logarithms, and exponential functions. Risch called it a decision procedure, because it is a method for deciding whether a function has an elementary function as an indefinite integral, and if it does, for determining that indefinite integral.<br>
      	The Risch algorithm is used to integrate elementary functions. These are functions obtained by composing exponentials, logarithms, radicals, trigonometric functions, and the four arithmetic operations (+ − × ÷).
      </p>
    </div>
  </div>

<div class="card border-light mb-3 Closest-Pair search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Closest-Pair Algorithm</h5>
      <p class="card-text">The closest pair of points problem or closest pair problem is a problem of computational geometry: given n points in metric space, find a pair of points with the smallest distance between them. The closest pair problem for points in the Euclidean plane[1] was among the first geometric problems that were treated at the origins of the systematic study of the computational complexity of geometric algorithms.<br><br>

A naive algorithm of finding distances between all pairs of points in a space of dimension d and selecting the minimum requires O(n2) time. It turns out that the problem may be solved in O(n log n) time in a Euclidean space or Lp space of fixed dimension d.[2] In the algebraic decision tree model of computation, the O(n log n) algorithm is optimal, by a reduction from the element uniqueness problem. In the computational model that assumes that the floor function is computable in constant time the problem can be solved in O(n log log n) time.[3] If we allow randomization to be used together with the floor function, the problem can be solved in O(n) time.
      </p>
    </div>
  </div>

<div class="card border-light mb-3 Gilbert-Johnson-Keerthi-Distance search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Gilbert-Johnson-Keerthi-Distance Algorithm</h5>
      <p class="card-text">The Gilbert–Johnson–Keerthi distance algorithm is a method of determining the minimum distance between two convex sets. Unlike many other distance algorithms, it does not require that the geometry data be stored in any specific format, but instead relies solely on a support function to iteratively generate closer simplices to the correct answer using the configuration space obstacle (CSO) of two convex shapes, more commonly known as the Minkowski difference.<br>

"Enhanced GJK" algorithms use edge information to speed up the algorithm by following edges when looking for the next simplex. This improves performance substantially for polytopes with large numbers of vertices.<br>

GJK makes use of Johnson's distance subalgorithm, which computes in the general case the point of a tetrahedron closest to the origin, but is known to suffer from numerical robustness problems. In 2017 Montanari, Petrinic, and Barbieri proposed a new subalgorithm based on signed volumes which avoids the multiplication of potentially small quantities and achieved a speedup of 15% to 30%.<br>

GJK algorithms are often used incrementally in simulation systems and video games. In this mode, the final simplex from a previous solution is used as the initial guess in the next iteration, or "frame". If the positions in the new frame are close to those in the old frame, the algorithm will converge in one or two iterations. This yields collision detection systems which operate in near-constant time.<br>
      </p>
    </div>
  </div>

  <div class="card border-light mb-3 Euclidean-Distance-Transform search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Euclidean-Distance-Transform  Algorithm</h5>
      <p class="card-text">A distance transform, also known as distance map or distance field, is a derived representation of a digital image. The choice of the term depends on the point of view on the object in question: whether the initial image is transformed into another representation, or it is simply endowed with an additional map or field.

Distance fields can also be signed, in the case where it is important to distinguish whether the point is inside or outside of the shape.<br><br>
Usually the transform/map is qualified with the chosen metric. For example, one may speak of Manhattan distance transform, if the underlying metric is Manhattan distance.<br> Common metrics are:

<ul><li>Euclidean distance</li>
<li>Taxicab geometry, also known as City block distance or Manhattan distance.</li>
<li>Chebyshev distance</li></ul>
      </p>
    </div>
  </div>

  <div class="card border-light mb-3 Nearest-Neighbour-Search search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Nearest-Neighbour-Search Algorithm</h5>
      <p class="card-text">Nearest neighbor search (NNS), as a form of proximity search, is the optimization problem of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values.<br>

Formally, the nearest-neighbor (NN) search problem is defined as follows: given a set S of points in a space M and a query point q ∈ M, find the closest point in S to q. Donald Knuth in vol. 3 of The Art of Computer Programming (1973) called it the post-office problem, referring to an application of assigning to a residence the nearest post office. A direct generalization of this problem is a k-NN search, where we need to find the k closest points.
      </p>
    </div>
  </div>

  <div class="card border-light mb-3 Collision-Detection search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Collision-Detection Algorithm</h5>
      <p class="card-text">Collision detection is the computational problem of detecting the intersection of two or more objects. Collision detection is a classic issue of computational geometry and has applications in various computing fields, primarily in computer graphics, computer games, computer simulations, robotics and computational physics. Collision detection algorithms can be divided into operating on 2D and 3D objects.
      </p>
    </div>
  </div>

  <div class="card border-light mb-3 Cone search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Cone Algorithm</h5>
      <p class="card-text">In computational geometry, the cone algorithm is an algorithm for identifying the particles that are near the surface of an object composed of discrete particles. Its applications include computational surface science and computational nano science. The cone algorithm was first described in a publication about nanogold in 2005.<br><br>

The cone algorithm works well with clusters in condensed phases, including solid and liquid phases. It can handle the situations when one configuration includes multiple clusters or when holes exist inside clusters. It can also be applied to a cluster iteratively to identify multiple sub-surface layers.
      </p>
    </div>
  </div>

  <div class="card border-light mb-3 Jump-and-Walk search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Jump-and-Walk Algorithm</h5>
      <p class="card-text">Jump-and-Walk is an algorithm for point location in triangulations (though most of the theoretical analysis were performed in 2D and 3D random Delaunay triangulations). Surprisingly, the algorithm does not need any preprocessing or complex data structures except some simple representation of the triangulation itself. The predecessor of Jump-and-Walk was due to Lawson (1977) and Green and Sibson (1978), which picks a random starting point S and then walks from S toward the query point Q one triangle at a time. Jump-and-Walk picks a small group of sample points and starts the walk from the sample point which is the closest to Q until the simplex containing Q is found.
      </p>
    </div>
  </div>

  <div class="card border-light mb-3 Laplacian-Smoothing search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Laplacian-Smoothing Algorithm</h5>
      <p class="card-text">Laplacian smoothing is an algorithm to smooth a polygonal mesh.[1][2] For each vertex in a mesh, a new position is chosen based on local information (such as the position of neighbors) and the vertex is moved there. In the case that a mesh is topologically a rectangular grid (that is, each internal vertex is connected to four neighbors) then this operation produces the Laplacian of the mesh.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Bentley-Ottmann search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Bentley-Ottmann Algorithm</h5>
      <p class="card-text">In computational geometry, the Bentley–Ottmann algorithm is a sweep line algorithm for listing all crossings in a set of line segments, i.e. it finds the intersection points (or, simply, intersections) of line segments. It extends the Shamos–Hoey algorithm,[1] a similar previous algorithm for testing whether or not a set of line segments has any crossings.<br><br>
      	The main idea of the Bentley–Ottmann algorithm is to use a sweep line approach, in which a vertical line L moves from left to right (or, e.g., from top to bottom) across the plane, intersecting the input line segments in sequence as it moves.[2] The algorithm is described most easily in its general position, meaning:

<ul><li>No two line segment endpoints or crossings have the same x-coordinate</li>
<li>No line segment endpoint lies upon another line segment</li>
<li>No three line segments intersect at a single point.</li></ul>
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Ray-Casting search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Ray-Casting Algorithm</h5>
      <p class="card-text">Ray casting is the most basic of many computer graphics rendering algorithms that use the geometric algorithm of ray tracing. Ray tracing-based rendering algorithms operate in image order to render three-dimensional scenes to two-dimensional images. Geometric rays are traced from the eye of the observer to sample the light (radiance) travelling toward the observer from the ray direction. The speed and simplicity of ray casting comes from computing the color of the light without recursively tracing additional rays that sample the radiance incident on the point that the ray hit. This eliminates the possibility of accurately rendering reflections, refractions, or the natural falloff of shadows; however all of these elements can be faked to a degree, by creative use of texture maps or other methods. The high speed of calculation made ray casting a handy rendering method in early real-time 3D video games.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Winding-Number search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Winding-Number Algorithm</h5>
      <p class="card-text">Winding number is defined by the number of times a curve travels counter clockwise around a point. The algorithm states that for any point inside the polygon the winding number would be non zero. Therefore it also know as the nonzero-rule algorithm
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Shoelace search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Shoelace Algorithm</h5>
      <p class="card-text">The shoelace formula or shoelace algorithm (also known as Gauss's area formula and the surveyor's formula[1]) is a mathematical algorithm to determine the area of a simple polygon whose vertices are described by their Cartesian coordinates in the plane.[2] The user cross-multiplies corresponding coordinates to find the area encompassing the polygon, and subtracts it from the surrounding polygon to find the area of the polygon within. The area formula can also be applied to self-overlapping polygons since the meaning of area is still clear even though self-overlapping polygons are not generally simple.[5] Furthermore, a self-overlapping polygon can have multiple "interpretations" but the Shoelace formula can be used to show that the polygon's area is the same regardless of the interpretation.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Euclidean search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Euclidean Algorithm</h5>
      <p class="card-text">In mathematics, the Euclidean algorithm,[note 1] or Euclid's algorithm, is an efficient method for computing the greatest common divisor (GCD) of two integers (numbers), the largest number that divides them both without a remainder. The Euclidean algorithm is based on the principle that the greatest common divisor of two numbers does not change if the larger number is replaced by its difference with the smaller number.<br>
      	It is used for reducing fractions to their simplest form and for performing division in modular arithmetic. Computations using this algorithm form part of the cryptographic protocols that are used to secure internet communications, and in methods for breaking these cryptosystems by factoring large composite numbers. 
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Extended-Euclidean search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Extended-Euclidean Algorithm</h5>
      <p class="card-text">In arithmetic and computer programming, the extended Euclidean algorithm is an extension to the Euclidean algorithm, and computes, in addition to the greatest common divisor (gcd) of integers a and b, also the coefficients of Bézout's identity, which are integers x and y such that<br>

ax + by = gcd(a,b)<br>
This is a certifying algorithm, because the gcd is the only number that can simultaneously satisfy this equation and divide the inputs. It allows one to compute also, with almost no extra cost, the quotients of a and b by their greatest common divisor.

Extended Euclidean algorithm also refers to a very similar algorithm for computing the polynomial greatest common divisor and the coefficients of Bézout's identity of two univariate polynomials.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Schonhage-Strassen search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Schonhage-Strassen Algorithm</h5>
      <p class="card-text">The Schönhage–Strassen algorithm is an asymptotically fast multiplication algorithm for large integers. It was developed by Arnold Schönhage and Volker Strassen in 1971.[1] The run-time bit complexity is, in Big O notation, O(n*logn*log logn) for two n-digit numbers. The algorithm uses recursive Fast Fourier transforms in rings with 2n+1 elements, a specific type of number theoretic transform.<br>
      	Applications of the Schönhage–Strassen algorithm include mathematical empiricism, such as the Great Internet Mersenne Prime Search and computing approximations of π, as well as practical applications such as Kronecker substitution, in which multiplication of polynomials with integer coefficients can be efficiently reduced to large integer multiplication; this is used in practice by GMP-ECM for Lenstra elliptic curve factorization
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Odlyzko-Schonhage search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Odlyzko-Schonhage Algorithm</h5>
      <p class="card-text">In mathematics, the Odlyzko–Schönhage algorithm is a fast algorithm for evaluating the Riemann zeta function at many points, introduced by (Odlyzko & Schönhage 1988). The main point is the use of the fast Fourier transform to speed up the evaluation of a finite Dirichlet series of length N at O(N) equally spaced value. The algorithm can be used not just for the Riemann zeta function, but also for many other functions given by Dirichlet series.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Borwein's search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Borwein's Algorithm</h5>
      <p class="card-text">In mathematics, Borwein's algorithm is an algorithm devised by Jonathan and Peter Borwein to calculate the value of 1/π. They devised several other algorithms. They published the book Pi and the AGM – A Study in Analytic Number Theory and Computational Complexity.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Chudnovsky Algorithm search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Chudnovsky Algorithm</h5>
      <p class="card-text">The Chudnovsky algorithm is a fast method for calculating the digits of π, based on Ramanujan’s π formulae. This identity is similar to some of Ramanujan's formulas involving π,[2] and is an example of a Ramanujan–Sato series.

The time complexity of the algorithm is O(nlog(n^3))
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Bailey-Borwein-Plouffe-Formula search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Bailey-Borwein-Plouffe-Formula Algorithm</h5>
      <p class="card-text">The Bailey–Borwein–Plouffe formula (BBP formula) is a formula for π. The BBP formula gives rise to a spigot algorithm for computing the nth base-16 (hexadecimal) digit of π (and therefore also the nth binary digit of π) without computing the preceding digits. This does not compute the nth decimal of π (i.e., in base 10). Such a result for base 10 is not known.
The existence of this formula came as a surprise. It had been widely believed that computing the nth digit of π is just as hard as computing the first n digits.<br>
This algorithm computes π without requiring custom data types having thousands or even millions of digits. The method calculates the nth digit without calculating the first n − 1 digits and can use small, efficient data types.

Though the BBP formula can directly calculate the value of any given digit of π with less computational effort than formulas that must calculate all intervening digits, BBP remains linearithmic O(nlogn), whereby successively larger values of n require increasingly more time to calculate; that is, the "further out" a digit is, the longer it takes BBP to calculate it, just like the standard π-computing algorithms
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Addition-chain-Exponentiation search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Addition-chain-Exponentiation Algorithm</h5>
      <p class="card-text">In mathematics and computer science, optimal addition-chain exponentiation is a method of exponentiation by positive integer powers that requires a minimal number of multiplications. It works by creating the shortest addition chain that generates the desired exponent. Each exponentiation in the chain can be evaluated by multiplying two of the earlier exponentiation results. More generally, addition-chain exponentiation may also refer to exponentiation by non-minimal addition chains constructed by a variety of algorithms (since a shortest addition chain is very difficult to find). The shortest addition-chain algorithm requires no more multiplications than binary exponentiation and usually less.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Exponentiating-By-Squaring search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Exponentiating-By-Squaring Algorithm</h5>
      <p class="card-text">Exponentiating by squaring is an algorithm. It is used for quickly working out large integer powers of a number. It is also known as the square-and-multiply algorithm or binary exponentiation. It uses the binary expansion of the exponent. It is of quite general use, for example in modular arithmetic. This algorithm is much faster than the ordinary method to compute such a value. Multipliying x by itself, n operations are needed to calculate x n. But here, only log2(n) operations are needed.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Rayleigh-Quotient-Iteration search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Rayleigh-Quotient-Iteration Algorithm</h5>
      <p class="card-text">Rayleigh quotient iteration is an eigenvalue algorithm which extends the idea of the inverse iteration by using the Rayleigh quotient to obtain increasingly accurate eigenvalue estimates.

Rayleigh quotient iteration is an iterative method, that is, it delivers a sequence of approximate solutions that converges to a true solution in the limit. Very rapid convergence is guaranteed and no more than a few iterations are needed in practice to obtain a reasonable approximation. The Rayleigh quotient iteration algorithm converges cubically for Hermitian or symmetric matrices, given an initial vector that is sufficiently close to an eigenvector of the matrix that is being analyzed. The algorithm is very similar to inverse iteration, but replaces the estimated eigenvalue at the end of each iteration with the Rayleigh quotient.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Gram-Schmidt search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Gram-Schmidt Algorithm</h5>
      <p class="card-text">In mathematics, particularly linear algebra and numerical analysis, the Gram–Schmidt process is a method for orthonormalizing a set of vectors in an inner product space, most commonly the Euclidean space Rn equipped with the standard inner product. The Gram–Schmidt process takes a finite, linearly independent set and generates an orthogonal set that spans the same k-dimensional subspace of Rn as S.<br>
      	The application of the Gram–Schmidt process to the column vectors of a full column rank matrix yields the QR decomposition (it is decomposed into an orthogonal and a triangular matrix).
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Strassen search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Strassen Algorithm</h5>
      <p class="card-text">In linear algebra, the Strassen algorithm, named after Volker Strassen, is an algorithm for matrix multiplication. It is faster than the standard matrix multiplication algorithm and is useful in practice for large matrices, but would be slower than the fastest known algorithms for extremely large matrices.<br>

Strassen's algorithm works for any ring, such as plus/multiply, but not all semirings, such as min-plus or boolean algebra, where the naive algorithm still works, and so called combinatorial matrix multiplication.
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Freivalds search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Freivald's Algorithm</h5>
      <p class="card-text">Freivalds' algorithm is a probabilistic randomized algorithm that works in time O(n2) with high probability. In O(kn2) time the algorithm can verify a matrix product with probability of failure less than 2-k. Since the output is not always correct, it is a Monte Carlo randomized algorithm. <br>
      	Freivalds' algorithm utilizes randomization in order to reduce this time bound to {\displaystyle O(n^2)with high probability. In O(k(n^2)) time the algorithm can verify a matrix product with probability of failure less than {\displaystyle 2^(-k)
      </p>
    </div>
  </div>  

  <div class="card border-light mb-3 Gauss-Jordan-Elimination search" style="max-width: 44rem;" id="yo">
    <div class="card-header">Mathematics Algorithm</div>
    <div class="card-body">
      <h5 class="card-title">Gauss-Jordan-Elimination Algorithm</h5>
      <p class="card-text">Gauss Jordan elimination is an algorithm that allows to transform a linear system into an equivalent system in reduced row echelon form. The aim of the Gauss Jordan elimination algorithm is to transform a linear system of K equations in $L$ unknowns
into an equivalent system (i.e., a system having the same solutions) in reduced row echelon form. <br><br>
As in Gaussian elimination, in order to improve the numerical stability of the algorithm, we usually perform partial pivoting in step 6, that is, we always choose the row interchange that moves the largest element (in absolute value) to the pivotal position. If we also exchange columns in order to maximize the absolute value of the pivot, then we are doing complete pivoting. See the lecture on Gaussian elimination for more details on partial and complete pivoting.
      </p>
    </div>
  </div>     
</div>
</div>
<script type="text/javascript" src="MATHEMATICS.js"></script>
</body>
</html>